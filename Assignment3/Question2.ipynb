{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yob_AmHeZyj6"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow.keras.layers as Layer\n",
        "\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "import tensorboard\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load CIFAR Dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = keras.datasets.cifar10.load_data()\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "x_train = train_images.reshape(-1, 32, 32, 3)\n",
        "x_test = test_images.reshape(-1, 32, 32, 3)"
      ],
      "metadata": {
        "id": "jxQVlOUkaY9h"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LeNet CNN**"
      ],
      "metadata": {
        "id": "uA9eKxPHa_qS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lenet_CNN = tf.keras.models.Sequential()\n",
        "\n",
        "lenet_CNN.add(Layer.Conv2D(6, (5, 5), padding='same', activation='relu'))\n",
        "lenet_CNN.add(Layer.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "\n",
        "lenet_CNN.add(Layer.Conv2D(16, (5, 5), padding='same', activation='relu'))\n",
        "lenet_CNN.add(Layer.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "\n",
        "lenet_CNN.add(Layer.Conv2D(120, (5, 5), padding='same', activation='relu'))\n",
        "\n",
        "lenet_CNN.add(Layer.Flatten())\n",
        "lenet_CNN.add(Layer.Dense(84))\n",
        "lenet_CNN.add(Layer.Activation('relu'))\n",
        "\n",
        "lenet_CNN.add(Layer.Dense(10))\n",
        "lenet_CNN.add(Layer.Activation('softmax'))\n",
        "\n",
        "lenet_CNN.compile(loss='sparse_categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=.001), metrics=['accuracy'])\n",
        "\n",
        "lenet_CNN.build(input_shape=(1,32,32,3))\n",
        "\n",
        "lenet_CNN.summary()\n",
        "\n",
        "\n",
        "logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='accuracy', min_delta=.0001, patience=3, verbose=5,\n",
        "    mode='auto', baseline=None, restore_best_weights=False\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Training the model.\n",
        "lenet_CNN.fit(\n",
        "    x_train,\n",
        "    train_labels, \n",
        "    batch_size=512,\n",
        "    epochs=25,\n",
        "    callbacks=[tensorboard_callback, early_stopping_callback])\n",
        "\n",
        "\n",
        "score = lenet_CNN.evaluate(x_test, test_labels)\n",
        "print('Test accuracy:', score[1])\n",
        "print('Test loss:', score[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_Qlo1VsafQ3",
        "outputId": "ba68ceb8-c881-41ed-9099-507229d5949d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_9 (Conv2D)           (1, 32, 32, 6)            456       \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (1, 16, 16, 6)           0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (1, 16, 16, 16)           2416      \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (1, 8, 8, 16)            0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (1, 8, 8, 120)            48120     \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (1, 7680)                 0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (1, 84)                   645204    \n",
            "                                                                 \n",
            " activation_6 (Activation)   (1, 84)                   0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (1, 10)                   850       \n",
            "                                                                 \n",
            " activation_7 (Activation)   (1, 10)                   0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 697,046\n",
            "Trainable params: 697,046\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "98/98 [==============================] - 2s 15ms/step - loss: 1.8319 - accuracy: 0.3409\n",
            "Epoch 2/25\n",
            "98/98 [==============================] - 1s 14ms/step - loss: 1.4953 - accuracy: 0.4660\n",
            "Epoch 3/25\n",
            "98/98 [==============================] - 1s 14ms/step - loss: 1.3581 - accuracy: 0.5168\n",
            "Epoch 4/25\n",
            "98/98 [==============================] - 1s 14ms/step - loss: 1.2488 - accuracy: 0.5578\n",
            "Epoch 5/25\n",
            "98/98 [==============================] - 1s 15ms/step - loss: 1.1745 - accuracy: 0.5865\n",
            "Epoch 6/25\n",
            "98/98 [==============================] - 1s 14ms/step - loss: 1.1088 - accuracy: 0.6109\n",
            "Epoch 7/25\n",
            "98/98 [==============================] - 1s 14ms/step - loss: 1.0526 - accuracy: 0.6334\n",
            "Epoch 8/25\n",
            "98/98 [==============================] - 1s 14ms/step - loss: 0.9909 - accuracy: 0.6538\n",
            "Epoch 9/25\n",
            "98/98 [==============================] - 1s 14ms/step - loss: 0.9628 - accuracy: 0.6638\n",
            "Epoch 10/25\n",
            "98/98 [==============================] - 1s 14ms/step - loss: 0.9129 - accuracy: 0.6820\n",
            "Epoch 11/25\n",
            "98/98 [==============================] - 1s 14ms/step - loss: 0.8752 - accuracy: 0.6953\n",
            "Epoch 12/25\n",
            "98/98 [==============================] - 1s 14ms/step - loss: 0.8401 - accuracy: 0.7081\n",
            "Epoch 13/25\n",
            "98/98 [==============================] - 1s 14ms/step - loss: 0.7977 - accuracy: 0.7231\n",
            "Epoch 14/25\n",
            "98/98 [==============================] - 1s 14ms/step - loss: 0.7675 - accuracy: 0.7336\n",
            "Epoch 15/25\n",
            "98/98 [==============================] - 1s 14ms/step - loss: 0.7372 - accuracy: 0.7454\n",
            "Epoch 16/25\n",
            "98/98 [==============================] - 1s 14ms/step - loss: 0.7004 - accuracy: 0.7585\n",
            "Epoch 17/25\n",
            "98/98 [==============================] - 1s 14ms/step - loss: 0.6787 - accuracy: 0.7645\n",
            "Epoch 18/25\n",
            "98/98 [==============================] - 1s 14ms/step - loss: 0.6429 - accuracy: 0.7758\n",
            "Epoch 19/25\n",
            "98/98 [==============================] - 1s 14ms/step - loss: 0.6091 - accuracy: 0.7902\n",
            "Epoch 20/25\n",
            "98/98 [==============================] - 1s 14ms/step - loss: 0.5822 - accuracy: 0.7979\n",
            "Epoch 21/25\n",
            "98/98 [==============================] - 1s 14ms/step - loss: 0.5409 - accuracy: 0.8139\n",
            "Epoch 22/25\n",
            "98/98 [==============================] - 1s 14ms/step - loss: 0.5118 - accuracy: 0.8237\n",
            "Epoch 23/25\n",
            "98/98 [==============================] - 1s 14ms/step - loss: 0.4870 - accuracy: 0.8327\n",
            "Epoch 24/25\n",
            "98/98 [==============================] - 1s 14ms/step - loss: 0.4638 - accuracy: 0.8409\n",
            "Epoch 25/25\n",
            "98/98 [==============================] - 1s 14ms/step - loss: 0.4285 - accuracy: 0.8554\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.0778 - accuracy: 0.6763\n",
            "Test accuracy: 0.6762999892234802\n",
            "Test loss: 1.0778272151947021\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feedforward network**"
      ],
      "metadata": {
        "id": "z6VMNln7brcH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feed_forward_nw = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(32, 32, 3)),\n",
        "    keras.layers.Dense(6, activation='relu'),\n",
        "    keras.layers.Dense(16, activation='relu'),\n",
        "    keras.layers.Dense(120, activation='relu'),\n",
        "    keras.layers.Dense(84, activation='relu'),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "feed_forward_nw.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "feed_forward_nw.summary()\n",
        "\n",
        "\n",
        "\n",
        "logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "\n",
        "# Training the model.\n",
        "feed_forward_nw.fit(\n",
        "    x_train,\n",
        "    train_labels, \n",
        "    batch_size=512,\n",
        "    epochs=25,\n",
        "    callbacks=[tensorboard_callback])\n",
        "\n",
        "# Evaluate\n",
        "score = feed_forward_nw.evaluate(x_test, test_labels)\n",
        "\n",
        "print('Test accuracy:', score[1])\n",
        "print('Test loss:', score[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vh_jF4ajaliq",
        "outputId": "d9659983-3a95-48e0-c5fd-aee98afb0c14"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_4 (Flatten)         (None, 3072)              0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 6)                 18438     \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 16)                112       \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 120)               2040      \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 84)                10164     \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31,604\n",
            "Trainable params: 31,604\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 2.3030 - accuracy: 0.0969\n",
            "Epoch 2/25\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 2.3027 - accuracy: 0.0963\n",
            "Epoch 3/25\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 2.3027 - accuracy: 0.0969\n",
            "Epoch 4/25\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 2.3026 - accuracy: 0.0973\n",
            "Epoch 5/25\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 2.3026 - accuracy: 0.0984\n",
            "Epoch 6/25\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 2.3026 - accuracy: 0.0973\n",
            "Epoch 7/25\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 2.3026 - accuracy: 0.0976\n",
            "Epoch 8/25\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 2.3026 - accuracy: 0.0980\n",
            "Epoch 9/25\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 2.3026 - accuracy: 0.0979\n",
            "Epoch 10/25\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 2.3026 - accuracy: 0.0995\n",
            "Epoch 11/25\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 2.3026 - accuracy: 0.0963\n",
            "Epoch 12/25\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 2.3026 - accuracy: 0.0980\n",
            "Epoch 13/25\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 2.3026 - accuracy: 0.0997\n",
            "Epoch 14/25\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 2.3026 - accuracy: 0.0992\n",
            "Epoch 15/25\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 2.3026 - accuracy: 0.0977\n",
            "Epoch 16/25\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 2.3026 - accuracy: 0.0983\n",
            "Epoch 17/25\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 2.3026 - accuracy: 0.0988\n",
            "Epoch 18/25\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 2.3026 - accuracy: 0.0986\n",
            "Epoch 19/25\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 2.3026 - accuracy: 0.0959\n",
            "Epoch 20/25\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 2.3026 - accuracy: 0.0982\n",
            "Epoch 21/25\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 2.3027 - accuracy: 0.0985\n",
            "Epoch 22/25\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 2.3026 - accuracy: 0.0986\n",
            "Epoch 23/25\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 2.3026 - accuracy: 0.0991\n",
            "Epoch 24/25\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 2.3026 - accuracy: 0.0987\n",
            "Epoch 25/25\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 2.3026 - accuracy: 0.0954\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.1000\n",
            "Test accuracy: 0.10000000149011612\n",
            "Test loss: 2.3025858402252197\n"
          ]
        }
      ]
    }
  ]
}